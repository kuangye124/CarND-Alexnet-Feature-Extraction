{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPgBMeig7QHI/ulIu3mjV8K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I9ztH_LAEFAF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"c74307e0-6c70-428a-cd60-7721015b35f0","executionInfo":{"status":"ok","timestamp":1590457212436,"user_tz":240,"elapsed":29886,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IqWqUInQGoxx","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/CarND-Alexnet-Feature-Extraction')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AYk6UM0OHYxJ","colab_type":"text"},"source":["# **Imaginenet_Interference**"]},{"cell_type":"code","metadata":{"id":"VkHzj1vjHjQh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"731eadac-824e-4b96-866f-bb8c2ab501b0","executionInfo":{"status":"ok","timestamp":1590457253464,"user_tz":240,"elapsed":35664,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}}},"source":["# NOTE: You don't need to edit this code.\n","%tensorflow_version 1.x\n","import time\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib.pyplot import imread\n","from caffe_classes import class_names\n","from alexnet import AlexNet\n","\n","\n","# placeholders\n","x = tf.placeholder(tf.float32, (None, 227, 227, 3))\n","\n","# By keeping `feature_extract` set to `False`\n","# we indicate to keep the 1000 class final layer\n","# originally used to train on ImageNet.\n","probs = AlexNet(x, feature_extract=False)\n","init = tf.global_variables_initializer()\n","sess = tf.Session()\n","sess.run(init)\n","\n","# Read Images\n","im1 = (imread(\"/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/poodle.png\")[:, :, :3] * 255).astype(np.float32)\n","im1 = im1 - np.mean(im1)\n","\n","im2 = (imread(\"/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/weasel.png\")[:, :, :3] * 255).astype(np.float32)\n","im2 = im2 - np.mean(im2)\n","\n","# Run Inference\n","t = time.time()\n","output = sess.run(probs, feed_dict={x: [im1, im2]})\n","\n","# Print Output\n","for input_im_ind in range(output.shape[0]):\n","    inds = np.argsort(output)[input_im_ind, :]\n","    print(\"Image\", input_im_ind)\n","    for i in range(5):\n","        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n","    print()\n","\n","print(\"Time: %.3f seconds\" % (time.time() - t))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","WARNING:tensorflow:From /content/drive/My Drive/CarND-Alexnet-Feature-Extraction/alexnet.py:66: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Image 0\n","miniature poodle: 0.389\n","toy poodle: 0.223\n","Bedlington terrier: 0.173\n","standard poodle: 0.150\n","komondor: 0.026\n","\n","Image 1\n","weasel: 0.331\n","polecat, fitch, foulmart, foumart, Mustela putorius: 0.280\n","black-footed ferret, ferret, Mustela nigripes: 0.210\n","mink: 0.081\n","Arctic fox, white fox, Alopex lagopus: 0.027\n","\n","Time: 6.707 seconds\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yR6XPCtoQocm","colab_type":"text"},"source":["# **Traffic_Sign_Interference**"]},{"cell_type":"code","metadata":{"id":"aOInfIDOQvYK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"99581e02-8531-4300-ceaa-b09f00a94a57","executionInfo":{"status":"ok","timestamp":1590451368868,"user_tz":240,"elapsed":9877,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}}},"source":["x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n","# TODO: Resize the images so they can be fed into AlexNet.\n","# HINT: Use `tf.image.resize_images` to resize the images\n","resized = tf.image.resize_images(x, (227,227))\n","\n","assert resized is not Ellipsis, \"resized needs to modify the placeholder image size to (227,227)\"\n","probs = AlexNet(resized)\n","\n","init = tf.global_variables_initializer()\n","sess = tf.Session()\n","sess.run(init)\n","\n","# Read Images\n","im1 = imread(\"/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/construction.jpg\").astype(np.float32)\n","im1 = im1 - np.mean(im1)\n","\n","im2 = imread(\"/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/stop.jpg\").astype(np.float32)\n","im2 = im2 - np.mean(im2)\n","\n","# Run Inference\n","t = time.time()\n","output = sess.run(probs, feed_dict={x: [im1, im2]})\n","\n","# Print Output\n","for input_im_ind in range(output.shape[0]):\n","    inds = np.argsort(output)[input_im_ind, :]\n","    print(\"Image\", input_im_ind)\n","    for i in range(5):\n","        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n","    print()\n","\n","print(\"Time: %.3f seconds\" % (time.time() - t))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Image 0\n","screen, CRT screen: 0.051\n","digital clock: 0.041\n","laptop, laptop computer: 0.030\n","balance beam, beam: 0.027\n","parallel bars, bars: 0.023\n","\n","Image 1\n","digital watch: 0.395\n","digital clock: 0.275\n","bottlecap: 0.115\n","stopwatch, stop watch: 0.104\n","combination lock: 0.086\n","\n","Time: 0.141 seconds\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ranL4YOUS_Dk","colab_type":"text"},"source":["# **Feature_Extraction**"]},{"cell_type":"code","metadata":{"id":"m_AnY00sTCwe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"57a395fc-90b3-40ff-a514-6e59cbaedcd7","executionInfo":{"status":"ok","timestamp":1590453504869,"user_tz":240,"elapsed":11357,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}}},"source":["import pandas as pd\n","\n","sign_names = pd.read_csv('/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/signnames.csv')\n","nb_classes = 43\n","\n","x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n","resized = tf.image.resize_images(x, (227, 227))\n","\n","# NOTE: By setting `feature_extract` to `True` we return\n","# the second to last layer.\n","fc7 = AlexNet(resized, feature_extract=True)\n","# TODO: Define a new fully connected layer followed by a softmax activation to classify\n","# the traffic signs. Assign the result of the softmax activation to `probs` below.\n","# HINT: Look at the final layer definition in alexnet.py to get an idea of what this\n","# should look like.\n","shape = (fc7.get_shape().as_list()[-1], nb_classes)  # use this shape for the weight matrix\n","fc8W = tf.Variable(tf.truncated_normal(shape))\n","fc8b = tf.Variable(tf.zeros(nb_classes))\n","logits = tf.matmul(fc7, fc8W) + fc8b\n","probs = tf.nn.softmax(logits)\n","\n","init = tf.global_variables_initializer()\n","sess = tf.Session()\n","sess.run(init)\n","\n","# Read Images\n","im1 = imread(\"/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/construction.jpg\").astype(np.float32)\n","im1 = im1 - np.mean(im1)\n","\n","im2 = imread(\"/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/stop.jpg\").astype(np.float32)\n","im2 = im2 - np.mean(im2)\n","\n","# Run Inference\n","t = time.time()\n","output = sess.run(probs, feed_dict={x: [im1, im2]})\n","\n","# Print Output\n","for input_im_ind in range(output.shape[0]):\n","    inds = np.argsort(output)[input_im_ind, :]\n","    print(\"Image\", input_im_ind)\n","    for i in range(5):\n","        print(\"%s: %.3f\" % (sign_names.iloc[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n","    print()\n","\n","print(\"Time: %.3f seconds\" % (time.time() - t))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Image 0\n","Keep left: 1.000\n","Traffic signals: 0.000\n","Children crossing: 0.000\n","Bicycles crossing: 0.000\n","Double curve: 0.000\n","\n","Image 1\n","Double curve: 0.996\n","Speed limit (100km/h): 0.004\n","No passing for vechiles over 3.5 metric tons: 0.000\n","General caution: 0.000\n","Dangerous curve to the left: 0.000\n","\n","Time: 0.152 seconds\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hbi73Vu3b-IM","colab_type":"text"},"source":["# **Train_Feature_Extraction**"]},{"cell_type":"code","metadata":{"id":"-9xUW5CmcD92","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"outputId":"e122292d-7da0-4ef9-b166-795ee64c5458","executionInfo":{"status":"ok","timestamp":1590458471433,"user_tz":240,"elapsed":398822,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}}},"source":["import pickle\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","# TODO: Load traffic signs data.\n","training_file = '/content/drive/My Drive/CarND-Alexnet-Feature-Extraction/train.p'\n","with open(training_file, mode='rb') as f:\n","    data = pickle.load(f)\n","X, y = data['features'], data['labels']\n","\n","# TODO: Split data into training and validation sets.\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# TODO: Define placeholders and resize operation.\n","x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n","resized = tf.image.resize_images(x, (227, 227))\n","y = tf.placeholder(tf.int32, (None))\n","one_hot_y = tf.one_hot(y, 43)\n","\n","# TODO: pass placeholder as first argument to `AlexNet`.\n","fc7 = AlexNet(resized, feature_extract=True)\n","# NOTE: `tf.stop_gradient` prevents the gradient from flowing backwards\n","# past this point, keeping the weights before and up to `fc7` frozen.\n","# This also makes training faster, less work to do!\n","fc7 = tf.stop_gradient(fc7)\n","\n","# TODO: Add the final layer for traffic sign classification.\n","nb_classes = 43\n","shape = (fc7.get_shape().as_list()[-1], nb_classes)  # use this shape for the weight matrix\n","fc8W = tf.Variable(tf.truncated_normal(shape))\n","fc8b = tf.Variable(tf.zeros(nb_classes))\n","logits = tf.matmul(fc7, fc8W) + fc8b\n","\n","# TODO: Define loss, training, accuracy operations.\n","# HINT: Look back at your traffic signs project solution, you may\n","# be able to reuse some the code.\n","rate = 0.01\n","EPOCHS = 10\n","BATCH_SIZE = 128\n","\n","cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n","loss_operation = tf.reduce_mean(cross_entropy)\n","optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n","training_operation = optimizer.minimize(loss_operation)\n","\n","prediction = tf.argmax(logits, 1)\n","correct_prediction = tf.equal(prediction, tf.argmax(one_hot_y, 1))\n","accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","saver = tf.train.Saver()\n","\n","def evaluate(X_data, y_data):\n","    num_examples = len(X_data)\n","    total_accuracy = 0\n","    sess = tf.get_default_session()\n","    for offset in range(0, num_examples, BATCH_SIZE):\n","        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n","        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n","        total_accuracy += (accuracy * len(batch_x))\n","    return total_accuracy / num_examples\n","\n","# TODO: Train and evaluate the feature extraction model.\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    num_examples = len(X_train)\n","    \n","    print(\"Training...\")\n","    print()\n","    for i in range(EPOCHS):\n","        X_train, y_train = shuffle(X_train, y_train)\n","        for offset in range(0, num_examples, BATCH_SIZE):\n","            end = offset + BATCH_SIZE\n","            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n","            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n","            \n","        validation_accuracy = evaluate(X_valid, y_valid)\n","        print(\"EPOCH {} ...\".format(i+1))\n","        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n","        print()\n","        \n","    saver.save(sess, './AlexNet')\n","    print(\"Model saved\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Training...\n","\n","EPOCH 1 ...\n","Validation Accuracy = 0.704\n","\n","EPOCH 2 ...\n","Validation Accuracy = 0.800\n","\n","EPOCH 3 ...\n","Validation Accuracy = 0.866\n","\n","EPOCH 4 ...\n","Validation Accuracy = 0.881\n","\n","EPOCH 5 ...\n","Validation Accuracy = 0.887\n","\n","EPOCH 6 ...\n","Validation Accuracy = 0.906\n","\n","EPOCH 7 ...\n","Validation Accuracy = 0.916\n","\n","EPOCH 8 ...\n","Validation Accuracy = 0.912\n","\n","EPOCH 9 ...\n","Validation Accuracy = 0.917\n","\n","EPOCH 10 ...\n","Validation Accuracy = 0.912\n","\n","Model saved\n"],"name":"stdout"}]}]}